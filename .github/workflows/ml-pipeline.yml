name: ML Pipeline - Advanced

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * 1'  # Jalankan setiap Senin jam 2 pagi

jobs:
  data-validation:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy scikit-learn jupyter great-expectations
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Validate raw data
      run: |
        python -c "
        import pandas as pd
        import sys
        
        # Validasi data
        try:
            df = pd.read_csv('heart.csv')
            print(f'Data shape: {df.shape}')
            print(f'Missing values: {df.isnull().sum().sum()}')
            
            # Cek apakah data tidak kosong
            if df.empty:
                print('ERROR: Data kosong!')
                sys.exit(1)
            
            # Cek kolom yang diperlukan
            required_cols = ['age', 'sex', 'cp', 'trestbps']  # Sesuaikan dengan dataset Anda
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print(f'ERROR: Kolom hilang: {missing_cols}')
                sys.exit(1)
                
            print('âœ… Data validation passed!')
        except Exception as e:
            print(f'ERROR: {e}')
            sys.exit(1)
        "

  preprocessing:
    needs: data-validation
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy scikit-learn jupyter matplotlib seaborn
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Run preprocessing
      run: |
        python automate_Rafif.py
    
    - name: Upload preprocessing results
      uses: actions/upload-artifact@v3
      with:
        name: preprocessed-data
        path: heart_preprocessing/
    
    - name: Generate report
      run: |
        python -c "
        import pandas as pd
        import os
        
        # Buat laporan sederhana
        with open('preprocessing_report.txt', 'w') as f:
            f.write('=== PREPROCESSING REPORT ===\\n')
            f.write(f'Timestamp: $(date)\\n')
            
            if os.path.exists('heart_preprocessing'):
                files = os.listdir('heart_preprocessing')
                f.write(f'Generated files: {files}\\n')
            
            f.write('Preprocessing completed successfully!\\n')
        "
    
    - name: Upload report
      uses: actions/upload-artifact@v3
      with:
        name: preprocessing-report
        path: preprocessing_report.txt

  model-training:
    needs: preprocessing
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'  # Hanya di main branch
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy scikit-learn jupyter matplotlib seaborn joblib
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    
    - name: Download preprocessing results
      uses: actions/download-artifact@v3
      with:
        name: preprocessed-data
        path: heart_preprocessing/
    
    - name: Train model (simulasi)
      run: |
        python -c "
        import pandas as pd
        import numpy as np
        from sklearn.model_selection import train_test_split
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import accuracy_score
        import joblib
        import os
        
        print('ðŸ¤– Starting model training simulation...')
        
        # Simulasi training dengan data dummy jika file preprocessing tidak ada
        if os.path.exists('heart_preprocessing'):
            print('Using preprocessed data')
        else:
            print('Using original data for simulation')
            df = pd.read_csv('heart.csv')
            
            # Preprocessing sederhana
            X = df.select_dtypes(include=[np.number]).drop('target', axis=1, errors='ignore')
            y = df['target'] if 'target' in df.columns else np.random.randint(0, 2, len(df))
            
            # Split data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Train model
            model = RandomForestClassifier(n_estimators=100, random_state=42)
            model.fit(X_train, y_train)
            
            # Evaluate
            y_pred = model.predict(X_test)
            accuracy = accuracy_score(y_test, y_pred)
            
            print(f'Model accuracy: {accuracy:.4f}')
            
            # Save model
            joblib.dump(model, 'trained_model.pkl')
            print('âœ… Model saved successfully!')
        "
    
    - name: Upload model
      uses: actions/upload-artifact@v3
      with:
        name: trained-model
        path: trained_model.pkl
      if: success()
